{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rlixne56HZiS"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT\n",
      "patch 16\n",
      "damage 0.5\n"
     ]
    }
   ],
   "source": [
    "print('ViT')\n",
    "print('patch 16')\n",
    "print('damage 0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W5pHivV1HZiW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\shubh\\anaconda3\\Lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.16.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.src.engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvit_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vit\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# from tensorflow.python.keras.engine.keras_tensor import KerasTensor\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\vit_keras\\vit.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtx\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, utils\n\u001b[0;32m      8\u001b[0m ConfigDict \u001b[38;5;241m=\u001b[39m tx\u001b[38;5;241m.\u001b[39mTypedDict(\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfigDict\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     },\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     19\u001b[0m CONFIG_B: ConfigDict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3072\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m768\u001b[39m,\n\u001b[0;32m     25\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\vit_keras\\layers.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# pylint: disable=arguments-differ,missing-function-docstring,missing-class-docstring,unexpected-keyword-arg,no-value-for-parameter\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mregister_keras_serializable()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClassToken\u001b[39;00m(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLayer):\n\u001b[0;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Append a class token to an input layer.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow_addons\\__init__.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m _check_tf_version()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Local project imports\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callbacks\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow_addons\\activations\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Additional activation functions.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgelu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gelu\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhardshrink\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hardshrink\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlisht\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lisht\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow_addons\\activations\\gelu.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorLike\n\u001b[0;32m     22\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mregister_keras_serializable(package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddons\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgelu\u001b[39m(x: TensorLike, approximate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gaussian Error Linear Unit.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    Computes gaussian error linear:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m        A `Tensor`. Has the same type as `x`.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow_addons\\utils\\types.py:29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# TODO: Remove once https://github.com/tensorflow/tensorflow/issues/44613 is resolved\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Version(tf\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mrelease \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.13\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelease:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# New versions of Keras require importing from `keras.src` when\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# importing internal symbols.\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m Version(tf\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mrelease \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelease:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.engine'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import skimage.exposure\n",
    "from numpy.random import default_rng\n",
    "import random\n",
    "import numpy as np\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from vit_keras import vit\n",
    "from tensorflow import keras\n",
    "# from tensorflow.python.keras.engine.keras_tensor import KerasTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Liqzo0gtHZie"
   },
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w = 4200\n",
    "img_h = 420\n",
    "channels = 3\n",
    "num_classes = 130\n",
    "batch_size = 16 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_function(image):\n",
    "    image = image / 255.0\n",
    "#     image = skimage.util.random_noise(image, mode='gaussian', var=1)\n",
    "#     image = skimage.util.random_noise(image, mode='s&p', amount=1)\n",
    "    image = skimage.util.random_noise(image, mode='speckle', var=1)\n",
    "    image = image * 255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def damage_function(image): \n",
    "    patch_size = 32\n",
    "    num_patches = img_h // patch_size * img_w // patch_size\n",
    "\n",
    "    for i in range(num_patches):\n",
    "        prob = 0.5\n",
    "        if random.choices([0, 1], [1-prob, prob])[0]:\n",
    "            image[(i//(img_w // patch_size))*patch_size:(i//(img_w // patch_size))*patch_size+patch_size, (i%(img_w // patch_size))*patch_size:(i%(img_w // patch_size))*patch_size+patch_size, :] = np.zeros([patch_size, patch_size, channels])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_damage_function(image):\n",
    "    image = image.astype(np.uint8)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # define random seed to change the pattern\n",
    "    rng = default_rng()\n",
    "\n",
    "    # create random noise image\n",
    "    noise = rng.integers(0, 255, (height,width), np.uint8, True)\n",
    "\n",
    "    # blur the noise image to control the size\n",
    "    blur = cv2.GaussianBlur(noise, (0,0), sigmaX=15, sigmaY=15, borderType = cv2.BORDER_DEFAULT)\n",
    "\n",
    "    # stretch the blurred image to full dynamic range\n",
    "    stretch = skimage.exposure.rescale_intensity(blur, in_range='image', out_range=(0,255)).astype(np.uint8)\n",
    "\n",
    "    # threshold stretched image to control the size\n",
    "    thresh = cv2.threshold(stretch, 175, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # apply morphology open and close to smooth out and make 3 channels\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,9))\n",
    "    mask = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.merge([mask,mask,mask])\n",
    "\n",
    "    # add mask to input\n",
    "    result = cv2.add(image, mask)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1300 images belonging to 130 classes.\n",
      "Found 260 images belonging to 130 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = damage_function\n",
    ")    \n",
    "\n",
    "train_ds = image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                directory= \"C:/Users/shubh/OneDrive/Desktop/IITP/Expeeriment Set3/train\",\n",
    "                                                shuffle=True,\n",
    "                                                target_size=(img_h, img_w),\n",
    "                                                class_mode = 'categorical')\n",
    "\n",
    "# validation_ds = image_generator.flow_from_directory(batch_size=batch_size,\n",
    "#                                                     directory='../../datasets/val',\n",
    "#                                                     shuffle=False,\n",
    "#                                                     target_size=(img_h, img_w),\n",
    "#                                                     class_mode = 'categorical')\n",
    "\n",
    "test_ds = image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                directory=\"C:/Users/shubh/OneDrive/Desktop/IITP/Expeeriment Set3/On_Off\",\n",
    "                                                shuffle=False,\n",
    "                                                target_size=(img_h, img_w),\n",
    "                                                class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16\n",
    "num_patches = img_h // patch_size * img_w // patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(tf.keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (32,32,3) into shape (4,32,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m      2\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      3\u001b[0m fig\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mset_facecolor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:112\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:328\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    326\u001b[0m         params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mget_random_transform(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    327\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mapply_transform(x, params)\n\u001b[1;32m--> 328\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstandardize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m     batch_x[i] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# optionally save augmented images to disk for debugging purposes\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1251\u001b[0m, in \u001b[0;36mImageDataGenerator.standardize\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the normalization configuration in-place to a batch of\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;124;03minputs.\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;124;03m    The inputs, normalized.\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessing_function:\n\u001b[1;32m-> 1251\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale:\n\u001b[0;32m   1253\u001b[0m     x \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrescale\n",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m, in \u001b[0;36mdamage_function\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      6\u001b[0m     prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mchoices([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mprob, prob])[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m----> 8\u001b[0m         \u001b[43mimage\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_w\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_w\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_w\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_w\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([patch_size, patch_size, channels])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (32,32,3) into shape (4,32,3)"
     ]
    }
   ],
   "source": [
    "image = next(train_ds)[0][0]/255.0\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.patch.set_facecolor('black')\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "# plt.savefig('./sample_data.png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "resized_image = tf.image.resize(tf.convert_to_tensor([image]), size=(img_h, img_w))\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {img_h} X {img_w}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = img_w // patch_size\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.patch.set_facecolor('black')\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                bottom=0.1,\n",
    "                right=0.9,\n",
    "                top=0.9,\n",
    "                wspace=0.3,\n",
    "                hspace=0.3)\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, channels))\n",
    "    plt.imshow(patch_img)\n",
    "    plt.axis(\"off\")\n",
    "# plt.savefig('./patches.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_h, img_w, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XZraYJOEHZjN"
   },
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    input = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = vit.preprocess_inputs(input)\n",
    "    base_model = vit.build_model(\n",
    "                image_size = (img_h, img_w),\n",
    "                patch_size = patch_size,\n",
    "                num_layers = 12,\n",
    "                hidden_size = 768,\n",
    "                num_heads = 12,\n",
    "                name = 'vit',\n",
    "                mlp_dim = 3072,\n",
    "                classes = num_classes,\n",
    "                dropout = 0.2,\n",
    "                activation = 'softmax'\n",
    "            )\n",
    "    output = base_model(x)\n",
    "    model = tf.keras.Model(inputs=input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vit_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_vit_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m, in \u001b[0;36mcreate_vit_classifier\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_vit_classifier\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[1;32m----> 3\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mvit\u001b[49m\u001b[38;5;241m.\u001b[39mpreprocess_inputs(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m      4\u001b[0m     base_model \u001b[38;5;241m=\u001b[39m vit\u001b[38;5;241m.\u001b[39mbuild_model(\n\u001b[0;32m      5\u001b[0m                 image_size \u001b[38;5;241m=\u001b[39m (img_h, img_w),\n\u001b[0;32m      6\u001b[0m                 patch_size \u001b[38;5;241m=\u001b[39m patch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m                 activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m             )\n\u001b[0;32m     16\u001b[0m     output \u001b[38;5;241m=\u001b[39m base_model(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vit' is not defined"
     ]
    }
   ],
   "source": [
    "vit_classifier = create_vit_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vit_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvit_classifier\u001b[49m\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vit_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "vit_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vit_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mvit_classifier\u001b[49m,\n\u001b[0;32m      3\u001b[0m     to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model.png\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m     show_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m     show_layer_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m     rankdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTB\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     expand_nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m     dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m96\u001b[39m,\n\u001b[0;32m     10\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m     show_layer_activations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vit_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    vit_classifier,\n",
    "    to_file='./model.png',\n",
    "    show_shapes=True,\n",
    "    show_dtype=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=True,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile, train, and evaluate the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "num_epochs = 300\n",
    "checkpoint_filepath = f\"../../weights/ViT_damage_0.5/{patch_size}/checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "\n",
    "vit_classifier.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor=\"val_accuracy\", save_best_only=True, save_weights_only=True),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=validation_ds,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('ViT loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.savefig('./loss.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('ViT accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='lower right')\n",
    "plt.savefig('./accuracy.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluate(model, test_ds):\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy = model.evaluate(test_ds)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    with open('results.txt', 'w') as f:\n",
    "        f.write(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluate(vit_classifier, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    print('ViT')\n",
    "    print('patch 16')\n",
    "    print('damage 0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_classification_with_vision_transformer",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-4.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "823f7b2671db007787d0db0546ea81831f91cc44f11498d06f7d8c9536fb94b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
